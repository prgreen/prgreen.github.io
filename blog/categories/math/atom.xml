<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Math | Professor Green]]></title>
  <link href="http://prgreen.github.io/blog/categories/math/atom.xml" rel="self"/>
  <link href="http://prgreen.github.io/"/>
  <updated>2013-09-12T00:48:02-07:00</updated>
  <id>http://prgreen.github.io/</id>
  <author>
    <name><![CDATA[Professor Green]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[True hackers need math]]></title>
    <link href="http://prgreen.github.io/blog/2013/09/11/hackers-need-math/"/>
    <updated>2013-09-11T04:26:00-07:00</updated>
    <id>http://prgreen.github.io/blog/2013/09/11/hackers-need-math</id>
    <content type="html"><![CDATA[<h1 id="and-an-intuitive-comprehension-of-whats-happening-in-their-code">(and an intuitive comprehension of what’s happening in their code)</h1>

<p>More and more software developers in the start-up world are the product of necessity. While their technical knowledge of programming is usually good, their understanding of mathematics is sometimes really disappointing, and is a real handicap in their job.</p>

<p>Now, don’t get me wrong, I’m not <em>particularly</em> good at math, and I’m an engineer so I should feel bad about it, but when I can constantly notice the flaws in my colleagues’ or friends’ work or reasoning, that makes it all the more alarming.</p>

<p>Math is indisputably at the heart of programming, the same way it’s the heart of physics, or engineering, or anything that allows us to understand or manipulate the evolution of reality in quantifiable ways.</p>

<p>From what I’ve seen, “genius hacker college dropout kids” seem to be the most affected by the lack of mathematical knowledge. To them programming is mastering the specificities of a technology and use it to create cool stuff fast, or as a means to disrupt society’s power balance in their favor. Since it’s a valuable skill after all, they obtain sufficient gratification from their coding skills alone, and they never get around to learning real math to help them progress past a certain critical point, which is a handicap in all but the most trivial problems a programmer has to face. So they end up plateauing pretty hard despite a promising start, and prefer abandoning coding altogether and just doing business. Only the more “mathematical” geniuses can continue enjoying programming for years in a somewhat autotelic fashion (I’m thinking John Carmack and his recent tech-heavy speech at QuakeCon 2013). </p>

<h2 id="a-few-tales-of-mathematical-ignorance">A few tales of mathematical ignorance</h2>

<p>I promise those people are actually brilliant professional coders otherwise, but not understanding the math behind what they do is definitely a source of problems.</p>

<hr />

<p><strong>Example 1</strong>: Implementing the <a href="http://en.wikipedia.org/wiki/Glicko_rating_system">Glicko</a> rating system (to assess players’ strength in an online game)</p>

<p>“Can you implement this formula?”</p>

<p>=&gt; “Wait, what’s a logarithm?”</p>

<p>(and then not understanding the difference between natural logarithm of ten in base e, and logarithm in base ten)</p>

<hr />

<p><strong>Example 2</strong>: </p>

<p>“If your background image is too heavy for our website, you can try drawing more uniformly colored areas instead of varying the shades everywhere.”</p>

<p>=&gt; “I don’t get it, if the image size doesn’t change, it has the same number of pixels so the download size remains the same for the users.”</p>

<p>No. Dude. No. Not even close. Images displayed on a website are in a compressed format! Try comparing a big image with white only (compression works perfectly, 1kB) and a an image with the same size and every single pixel set to a random value (compression becomes useless, your image now weighs a few MB…).</p>

<p>Information entropy, fast fourier transform, are complicated but useful notions.</p>

<hr />

<p><strong>Example 3</strong>:</p>

<p>Not a dialog, but I see a lot of programmers who like to obsess over time and space complexities (using a fragile understanding of big O notations), saying “I’ll just use quicksort because it has the best time complexity and I want it to be fast”.</p>

<p>Actually when sorting an input they should consider all the aspects: </p>

<ul>
  <li>
    <p>in some cases the size of the input will remain low enough that more “complex” but simpler to understand algorithms with more favourable multiplicative constants are faster.</p>
  </li>
  <li>
    <p>if the size of the input is high but there are very few possible values, bucket sort beats quicksort.</p>
  </li>
  <li>
    <p>circumstances can justify using other algorithms, for example if the input is received by chunks over the network and needs to be constantly sorted, heap sort might be more adapted. </p>
  </li>
</ul>

<h2 id="google-coding">“Google coding”</h2>

<p>Applying formulas or following recipes is no substitute for an intuitive understanding of what’s happening inside your code.</p>

<p>The general spirit of not wanting to think or do math but just “have fun” or “make something awesome” results in an annoying trend: the so-called “Google coders”, people who will use Google extensively to solve their problems, copy-paste and adapt some code without fully understanding what they’re doing, not really checking the internals, or wondering why it should work.</p>

<p>It’s OK to do that sometimes, and tapping into the internet hivemind might feel like a decent way to increase your productivity instantly. But mostly it’s just laziness.</p>

<p>There are indeed a few glaring flaws with this approach:</p>

<ul>
  <li>
    <p>You end up trying to connect black boxes of code together, with potential impedance mismatch or lack of general consistency in your project.</p>
  </li>
  <li>
    <p>How do you test code you don’t understand? How do you handle memory, errors, exceptions, tests, that were not in the original code because the author wanted to keep things simple?</p>
  </li>
  <li>
    <p>You don’t learn anything that you can reapply in the future in similar circumstances using principles extracted from your intuitive comprehension of the problem.</p>
  </li>
  <li>
    <p>If you don’t understand exactly what you need in your specific problem, your solution won’t exactly answer your problem.</p>
  </li>
  <li>
    <p>No progress or breakthrough in technology was ever made by people who sacrifice for comfort the need to think. </p>
  </li>
</ul>

<p>Many programmers have the right idea when they try to roll their own piece of software (like, coding your blog platform or yet another content management system), and only then use all the available tools and libraries made by others and refined by years of use, understanding the intent behind every design decision and API call.</p>

<p>One immense advantage is that, when something breaks, you already know or imagine how the internals are made, and you can easily go fix it yourself (instead of waiting for the maintainer to manifest himself).  </p>

<p>I would only use “google coding” in emergency situations, for fun coding marathons, where I would be convinced the code quality and maintainability matters less than getting something out in record time.</p>

<h2 id="worse-than-google-coders-microsoft-black-magic-coders">Worse than “Google coders”: “Microsoft black magic coders”</h2>

<p>I’m not talking about people who work for Microsoft itself, who, I’m sure, are mostly brilliant people with a true passion for programming, for which I have a lot of respect.</p>

<p>I’m talking about people who believe they can get all the complicated parts of programming out of programming.</p>

<p>I talk to some of my friends who work and code for very big companies and are forced to use Microsoft products everywhere. </p>

<p>Microsoft products are great and make everything easier, except when they break, and they break all the time. I’m not blaming Microsoft particularly, everything breaks all the time, it’s called entropy, and it’s an inevitable part of the physical universe. Everyone can realize that programming is inherently hard, and it’s inevitable that sometimes, people will use your program in unforeseeable ways.</p>

<p>What I could blame Microsoft for, however, is that trying to hide all the implementation details and making programming simpler for a generation of subpar brainwashed programmers makes it harder to fix the inevitable problems one will encounter.</p>

<p>When something breaks in a fully open source stack, it’s relatively easy to identify which part, where, to correct the problem, to submit a fix to the maintainers, etc. It’s a very good feeling for a programmer, and it trains a generation of people who understand what happens at every level in their code, which is very sound and satisfying.</p>

<p>Microsoft deprives people from this feeling, by making the disputable (but economically justified) strategy choice to make everything “their way”, close-sourced and with voluntary divergence from internationally accepted norms or open interoperable formats.</p>

<p>Every programmer who uses Microsoft products is treated like a child, maintained in a state of voluntary ignorance, brainwashed into accepting a mix of archaic constructs and new idiomatically named features, given comparatively lower powers for fear that they could break things, and when (inevitably) something does break, no one has any idea what’s actually happening, and they are forced to call “experts” to unblock the situation.</p>

<p>I like to call them “black magic coders” because they see programming as summoning the powers of the dark side and pray that they consent to help. If Microsoft doesn’t provide any specific magical way to do what they want, they are distraught and helpless because they have no idea how to reimplement the basics by themselves.</p>

<p>I’ve talked to a software engineer with years of experience working with .Net and C#, who had no idea whether the huge web app they were making used “regular” HTTP calls or Ajax. Everything had always been abstracted away to him, to the point he had trouble making the connection between Microsoft mumbo jumbo and the actual underlying technologies used. </p>

<p>They memorize acronyms, standardized solutions, common answers good enough to pass their Microsoft certificate, and have a Pavlovian relationship to programming. </p>

<p>It’s fine to abstract away the implementation details, but only if you know what’s behind them in case you need to know, which happens often with those hard-to-find bugs where you hit a limitation or implementation quirk of the underlying technology.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Perseverance and probability]]></title>
    <link href="http://prgreen.github.io/blog/2013/09/10/perseverance-and-probability/"/>
    <updated>2013-09-10T14:47:00-07:00</updated>
    <id>http://prgreen.github.io/blog/2013/09/10/perseverance-and-probability</id>
    <content type="html"><![CDATA[<p><strong>Problem: Trying n times something that has a 1 in n chance of success.</strong></p>

<p>For example, n = 2 means having 2 tries to guess the result of a coin flip.</p>

<p>For n = 6, you have 6 tries to guess the result of rolling a standard die.</p>

<p>The probability of success P can also be expressed as “one minus the probability of every try failing”.
$$
P(n) = 1 - \Big(1-\frac{1}{n}\Big)^n
$$</p>

<p>A surprisingly high number of people have a very flawed understanding of probabilities, even with mathematical backgrounds, and will just assume without thinking that P is always 1 or converges towards 1 as n goes to infinity. None of these propositions are true. </p>

<h2 id="what-is-the-limit-as-n-goes-to-infinity">What is the limit as n goes to infinity?</h2>

<p>If you try sufficiently hard something that has a very low chance of success, you will always succeed (your probability of success converges towards 1), so most people would be tempted to say that P converges towards 1. But that’s not the question.</p>

<p>The question is: if you try <em>exactly</em> n times something that has a 1 in n chance of success, and n grows very big, how good are your chances? Let’s call P the probability of success.</p>

<script type="math/tex; mode=display">
lim_{n\to\infty}P(n) = 1 - lim_{n\to\infty}\Big(1-\frac{1}{n}\Big)^n
</script>

<p>Numerically if you tried a few values of n you would realize that the right expression converges quickly towards a number that is neither 0 nor 1.</p>

<p>Remembering one of the definitions of <strong>e</strong>, the Euler number:</p>

<script type="math/tex; mode=display">
e = lim_{n\to\infty}\Big(1+\frac{1}{n}\Big)^n
</script>

<p>it becomes easy to realize that</p>

<script type="math/tex; mode=display">
lim_{n\to\infty}P(n) = 1 - e ^{-1} \approx 0.63212
</script>

<p>A <em>63% chance of success</em> means you’re a winner in the long term if you’re used to <em>trying a million times</em> something that has a <em>one in a million chance</em> of success.</p>

<h2 id="wacky-logic-les-shadoks">Wacky logic: “Les Shadoks”</h2>

<p><img class="center" src="/images/shadok.jpg"></p>

<blockquote>
  <p>“If there is one in a million chance to succeed, rush failing the 999,999 first tries.”</p>
</blockquote>

<p>During my childhood in France in the 90s, an old animated TV series from the late 60s called “Les Shadoks” was still running, that had been a significant cultural phenomenon among older generations. I remember it being very funny, and you should definitely check it out on Youtube if you understand French, and are prepared to feel overwhelmed with utter confusion and culture shock. Some of the ridiculously wrong and illogical Shadok mottos are still heard today in France, although since then end of the show less and less people know where they come from (“Pourquoi faire simple quand on peut faire compliqué ?” =&gt; “Why do it the easy way when you can do it the hard way?”).</p>

<p><img class="center" src="/images/shadok2.jpg"></p>

<blockquote>
  <p>“Better to pump even if nothing happens than to risk something worse happening by not pumping”</p>
</blockquote>

<p>It had the most bizarre, absurd and eerie stories, and an unhealthy obsession with useless and endless pumping, but more importantly for our current discussion, the Shadoks, stupid and ruthless bird-like creatures, keep dying in atrocious circumstances because of how flawed their “logic” is.</p>

<p>One example that particularly struck me as a child: the Shadoks want to build a rocket to travel from their dysfunctional home planet to the Earth. Their most renowned mathematician calculates that their plan has a one in a million chance of success, then claims that all they have to do is rebuild the same rocket over and over again until it inevitably works when they reach 1 million attempts.</p>

<blockquote>
  <p>“When one tries continuously, one ends up succeeding. Thus, the more one fails, the greater the chance that it will work.”</p>
</blockquote>

<p>Even 7 year-old me knew it couldn’t be right (and anyone who understands basic probabilities is warned specifically against this fallacy), but it took me years to figure out the real probability of success.</p>

<p>Approximately 63% is actually a pretty good chance for the Shadoks, given their general incompetence.</p>

<p><img class="center" src="/images/shadok3.jpeg"></p>

<blockquote>
  <p>The Shadok brain can only memorize 4 words, so they count using a base 4 number system. They were my first introduction to non-decimal bases, at age 7, or BU MEU. </p>
</blockquote>

<p><img class="center" src="/images/shadok4.gif"></p>

<p>Here’s a link to a video explaining Shadok counting (in French): <a href="http://www.youtube.com/watch?v=nm0cw6b1PMA">Shadok counting</a></p>

<h2 id="applied-probabilities-picking-up-women-or-men">Applied probabilities: picking up women (or men)</h2>

<p>What are the odds that a girl you meet randomly in public agrees immediately to date you? The chances are pretty slim (although you’d be surprised how much blunt honesty works), especially now that I know you’d rather spend your free time reading through my ramblings instead of going outside making friends or something.</p>

<p>But the point is: the chances are small, but non-negligible, let’s say 1%. Ask every woman you meet during the day, in public transportation, on the streets, and more often than not (63% if you ask 100 girls out), you will end up dating someone today with little effort (probably someone really easy or mentally unstable, but that’s your problem now).</p>

<p>No need for sophisticated matching algorithms, loneliness in our contemporary societies is easily solved by brute force<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>!</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>I am not liable for tragic misunderstandings of this sentence.<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tech | Bill Green]]></title>
  <link href="http://prgreen.github.io/blog/categories/tech/atom.xml" rel="self"/>
  <link href="http://prgreen.github.io/"/>
  <updated>2013-09-30T03:09:20-07:00</updated>
  <id>http://prgreen.github.io/</id>
  <author>
    <name><![CDATA[Bill Green]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Video games that help you do your job better]]></title>
    <link href="http://prgreen.github.io/blog/2013/09/26/video-games-that-help-you-do-your-job-better/"/>
    <updated>2013-09-26T10:05:00-07:00</updated>
    <id>http://prgreen.github.io/blog/2013/09/26/video-games-that-help-you-do-your-job-better</id>
    <content type="html"><![CDATA[<p>It appears that 20% of video games nowadays are “serious games” designed for professional training. </p>

<p>Can’t video games also be used as an integral part of your job? </p>

<h2 id="video-games-to-solve-real-problems">Video games to solve real problems?</h2>

<p>Imagine a game that solves real-life issues, or is fed with information from the real world that players can manipulate in meaningful ways to produce accurate results.</p>

<p>Instead of crushing candy, you’d be folding proteins to help the progress of science. Of course, it already exists.</p>

<p>But it turns out it’s not that easy to make a video game that still feels fun while accomplishing something meaningful. Most math problems are already solved better by computers, and the few problems that humans can solve better would feel extremely repetitive and artificial when shoehorned into games.</p>

<h2 id="augmented-reality-games">Augmented reality games</h2>

<p>A more promising way for video games to enter everyone’s lives is through augmented reality games, making “boring chores” or menial jobs more lively.</p>

<p>Imagine you work as a cook in a futuristic restaurant. In the future you’ll have screens in the kitchen, with realtime feedback from the customers. You’ll have information when people tweet their food, what they say about presentation, taste, etc. You can adjust the recipes, cooking, quantities, seasonings, with immediate feedback. Individual or general tastes can be made available to you so you can customise the food according to everyone’s needs. Every client’s special diet (kosher, vegetarian, vegan, gluten-free) can be immediately known and special iPad menus will display only the relevant items and allow immediate order without any need for intermediates (like, you know, waiters). Ambient music and decoration can be adjusted by the clients to automatically cater to their taste, etc.</p>

<p>It’s easy to imagine games between cooks to achieve the best cumulated score during the service, and have special rewards displayed on screen for “perfect” dishes or “best cook of the day”.</p>

<p>It would make people who work in all sorts of difficult jobs feel better when they have instant feedback to realize that their efforts are paying off. Hi-scores could be displayed in the restaurant on a front display, alongside a constantly updated list of the most successful dishes.</p>

<p>Being a garbageman could almost become funny and motivating if you had a realtime display on the sides of the truck of the quantity of trash accumulated since the beginning of the day, with a timer, compared to your best score. When you beat your best score or perform significantly well, a special cinematic and music reward you, and people in the vicinity are warned that they can send encouragement tweets displayed immediately on the sides of the truck, make money donations or gifts, etc.</p>

<p>Even the most humble jobs would get recognition. And feeling observed and having people giving you feedback for your job is the best way to entice you to improve continuously.</p>

<p>Depending on your level of cynicism it could be either the most pathetic excess of enslaving by entertainment and infantilization, or the best thing to ever happen to capitalism.</p>

<ul>
  <li>Games can motivate progress and easily give a sense of constant progression when there is no more.</li>
  <li>Games can make cooperation easier between coworkers by exchanging only the relevant information by design.</li>
  <li>Games can provide visual or sound indications for instantaneous feedback on your actions, and faster correction.</li>
</ul>

<p>If people can play a game as dull and boring as World of Warcraft for years (that’s an inflammatory but fair opinion), there is no doubt that even simple video games with your coworkers can motivate you to accomplish boring tasks just to unlock achievements or grind xp to get to the next level before the end of the day. You are literally being rewarded for pressing buttons all day in specific patterns, arrange and optimize numbers, this can actually be made useful in industry.</p>

<p>It’s the same strategy used to make children or dogs do things. You have to convince them it’s a game (like, cleaning their room or completing an obstacle course), and they will gladly do it.</p>

<p>It would be extremely perilous to introduce the concept to grown-ups, as they would probably feel insulted, but probably less so in the future, when pretty much everyone has lived in a culture of video games since childhood.</p>

<p>By providing a more direct link between actions and rewards, video gamification of the world is the solution to optimizing human performance in the workplace. </p>

<p>Just having publicly displayed visual indicators that you can influence, is already a powerful motor for human action, as they trigger hunter impulse and collective emulation. </p>

<p>Video games are one of the cheapest entertainment medium available, you only need a screen and any interaction device, they can be linked to real information or sensors, and produce real consequences. They enforce a given framework, a set of rules that no one can break. They are the ultimate tool for enslavement of the younger generations.</p>

<h2 id="threats">Threats</h2>

<p>There are obvious threats with video games everywhere in the workplace, mainly that it needs true employee involvement to work.</p>

<p>Also games might distract you too much from the real job. No game can fully encompass and evaluate all you need to do to be successful at your job, because they can only reflect reality as well as what is used as input to them. Anything that isn’t in the game, even when it would be beneficial, will not be done.</p>

<p>Consequently, evaluating employees based on game results can have nefarious consequences, it should remain “just” a game, with employees having a say at how it could be evolved or how new content could be added to reflect reality better.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Twitter use cases are infinite]]></title>
    <link href="http://prgreen.github.io/blog/2013/09/13/twitter-use-cases-are-infinite/"/>
    <updated>2013-09-13T02:11:00-07:00</updated>
    <id>http://prgreen.github.io/blog/2013/09/13/twitter-use-cases-are-infinite</id>
    <content type="html"><![CDATA[<p>There’s a fundamental problem with Twitter, that is also a blessing: No one knows exactly how it should be used.</p>

<p>If you look at a single tweet, it’s already a mess, it could have all kinds of form or function:</p>

<ul>
  <li>self-contained text-only</li>
  <li>retweet</li>
  <li>response that can only be understood with the previous tweets of the conversation</li>
  <li>“hey, check this out” (the message can be meaningless, sometimes it’s a summary) with a link to proper content</li>
  <li>a description of an image, with the image attached, where the image is probably the most important part</li>
  <li>varying, arbitrary, collision-vulnerable, manually attached hashtags. Some are only semantic (they add context to interpret what is written), some also have practical uses (regrouping Instagram pictures). Some are associated to a specific meaningful trend, some are just pleasantries.</li>
  <li>it could originate from a bot or a human, sometimes it’s hard to know. It could be from an individual, from a brand, from a group of people, from someone managing a celebrity account, from someone claiming to be someone else, etc.</li>
</ul>

<p>If you were to design the perfect and definitive “Twitter terminal” for every possible use of Twitter, you would have impossible ever-changing requirements. At the beginning for example, you could naively assume displaying text was enough, and an old non-smart phone with SMS capabilities was all you needed. But now you need images. You want geolocalization. You end up needing a complete web browser to follow URLs. Or even specialized software to extract meaning out of thousands of tweets.</p>

<p>This is why all sorts of third-party software exist: to help you make sense out of Twitter and provide new use cases.</p>

<p>Sure, patterns and “best practices” have emerged for typical personal use. But new ones can be imagined.</p>

<h2 id="whats-next">What’s next?</h2>

<p>Twitter is not just about individual micro-blogging anymore, especially with the introduction of premium accounts. It can simply be used as a generic platform for communication between companies/celebrities/gurus/content producers and the masses.</p>

<p>Companies want the publicity and feedback, masses want to be informed on the new products, make suggestions, and eventually buy stuff.</p>

<p>With the Twitter API, it’s easy to imagine infinitely many new use cases, based on “practical hashtags”, that can be used by customers to place orders when they send tweets to a specific company bot account.</p>

<p>Have order-by-tweet pizzerias. You send them your address once, then you place your orders when you want. A tweet is easier and more explicit than a phone call.
It has an associated timestamp and undeniable source, so you can check delivery speed claims, and there can be no ambiguity or shenanigans about who ordered what. With geolocalization added, you could be sitting on a park bench and still have your pizza delivered to you.</p>

<p>Of course, as of today, modern society assumes pretty much everyone has a phone, but you can’t assume everyone has a smartphone, or a Twitter account or knows how to use it or wants to. But the expectations of what is normal or not are shifting. In the future tweeting could be a ubiquitous activity any human being is assumed to be able to do, for a variety of purposes, like selecting entrees at a restaurant without the need to ever talk to a waiter (because you see, in the future people are all rendered socially awkward by all the time spent on their smartphones and computers). The telephone was widely adopted because of its practicality, and if Twitter can achieve the same level of practicality in its own domain, we can expect the same success in future generations.</p>

<p>Tweets as inputs to computer programs are not just useful to consumers, they help companies observe the realtime trends and act accordingly.</p>

<p>You can have social events with people voting by tweet instead of SMS (but hey, TV shows need the money).</p>

<p>If people have more incentives to tweet (I mean, more than social validation, tweets can get you stuff), if their tweet can trigger complex processes with more visible consequences, they will obviously tweet more and more people will tweet, all of which benefits Twitter.</p>

<p>Tweets in the future could be used as a way to trigger any verifiable transaction. Despite the outrage it would cause, Twitter might eventually offer <em>all</em> their users the possibility to confirm their real identity, because the possible applications are endless, from voting in elections to money transactions (now you have your viable business model, guys).</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vine is the new haiku]]></title>
    <link href="http://prgreen.github.io/blog/2013/09/13/vine-is-the-new-haiku/"/>
    <updated>2013-09-13T01:15:00-07:00</updated>
    <id>http://prgreen.github.io/blog/2013/09/13/vine-is-the-new-haiku</id>
    <content type="html"><![CDATA[<p>What is the consequence of forcing users to an incredibly constrained six seconds video format?</p>

<ul>
  <li>
    <p>The meaning is condensed. No more 5 minute video with only a few seconds of interesting action you could have skipped to directly. </p>
  </li>
  <li>
    <p>Consistency is enforced. There is just no time to tackle multiple subjects or be distracted from your original point.</p>
  </li>
  <li>
    <p>Ease of use. Anyone can make a 6 second video. Following the rules is not the hard part. </p>
  </li>
</ul>

<h2 id="its-twitter-all-over-again">It’s Twitter all over again</h2>

<p>The major trap with Vine or Twitter, or any fixed form of communication (haiku, sonnet, etc.), is that most people are tempted to use them for spontaneous (and usually meaningless) outbursts, when they should be carefully crafted and thought out for maximum impact.</p>

<h2 id="can-vine-really-be-advertised-as-a-new-art-form">Can Vine really be advertised as a new art form?</h2>

<p>In itself, Vine is only a vector for communication. It’s up to the people to use them as they want, the same way Twitter is used differently by brands, celebrities, ‘gurus’, teenagers, etc.</p>

<p>Conciseness has never been an obstacle to depth, and Vine is certainly capable of harboring art.</p>

<p>Sure, a lot of Vine videos are ADHD kids doing pointless crap, the same way most tweets are random angsty comments you could live without, and most haikus are mediocre attempts.</p>

<p>It doesn’t mean the form is flawed, but that it is used in frivolous ways.</p>

<p>Vine is currently experimental and teeming with general bizarrerie. But we can expect that it will stabilize, and that the same thing will happen to Vine that happened to Twitter:</p>

<p>People will learn to use it effectively.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[True hackers need math]]></title>
    <link href="http://prgreen.github.io/blog/2013/09/11/hackers-need-math/"/>
    <updated>2013-09-11T04:26:00-07:00</updated>
    <id>http://prgreen.github.io/blog/2013/09/11/hackers-need-math</id>
    <content type="html"><![CDATA[<h1 id="and-an-intuitive-comprehension-of-whats-happening-in-their-code">(and an intuitive comprehension of what’s happening in their code)</h1>

<p>More and more software developers in the start-up world are the product of necessity. While their technical knowledge of programming is usually good, their understanding of mathematics is sometimes really disappointing, and is a real handicap in their job.</p>

<p>Now, don’t get me wrong, I’m not <em>particularly</em> good at math, and I’m an engineer so I should feel bad about it, but when I can constantly notice the flaws in my colleagues’ or friends’ work or reasoning, that makes it all the more alarming.</p>

<p>Math is indisputably at the heart of programming, the same way it’s the heart of physics, or engineering, or anything that allows us to understand or manipulate the evolution of reality in quantifiable ways.</p>

<p>From what I’ve seen, “genius hacker college dropout kids” seem to be the most affected by the lack of mathematical knowledge. To them programming is mastering the specificities of a technology and use it to create cool stuff fast, or as a means to disrupt society’s power balance in their favor. Since it’s a valuable skill after all, they obtain sufficient gratification from their coding skills alone, and they never get around to learning real math to help them progress past a certain critical point, which is a handicap in all but the most trivial problems a programmer has to face. So they end up plateauing pretty hard despite a promising start, and prefer abandoning coding altogether and just doing business. Only the more “mathematical” geniuses can continue enjoying programming for years in a somewhat autotelic fashion (I’m thinking John Carmack and his recent tech-heavy speech at QuakeCon 2013). </p>

<h2 id="a-few-tales-of-mathematical-ignorance">A few tales of mathematical ignorance</h2>

<p>I promise those people are actually brilliant professional coders otherwise, but not understanding the math behind what they do is definitely a source of problems.</p>

<hr />

<p><strong>Example 1</strong>: Implementing the <a href="http://en.wikipedia.org/wiki/Glicko_rating_system">Glicko</a> rating system (to assess players’ strength in an online game)</p>

<p>“Can you implement this formula?”</p>

<p>=&gt; “Wait, what’s a logarithm?”</p>

<p>(and then not understanding the difference between natural logarithm of ten in base e, and logarithm in base ten)</p>

<hr />

<p><strong>Example 2</strong>: </p>

<p>“If your background image is too heavy for our website, you can try drawing more uniformly colored areas instead of varying the shades everywhere.”</p>

<p>=&gt; “I don’t get it, if the image size doesn’t change, it has the same number of pixels so the download size remains the same for the users.”</p>

<p>No. Dude. No. Not even close. Images displayed on a website are in a compressed format! Try comparing a big image with white only (compression works perfectly, 1kB) and a an image with the same size and every single pixel set to a random value (compression becomes useless, your image now weighs a few MB…).</p>

<p>Information entropy, fast fourier transform, are complicated but useful notions.</p>

<hr />

<p><strong>Example 3</strong>:</p>

<p>Not a dialog, but I see a lot of programmers who like to obsess over time and space complexities (using a fragile understanding of big O notations), saying “I’ll just use quicksort because it has the best time complexity and I want it to be fast”.</p>

<p>Actually when sorting an input they should consider all the aspects: </p>

<ul>
  <li>
    <p>in some cases the size of the input will remain low enough that more “complex” but simpler to understand algorithms with more favourable multiplicative constants are faster.</p>
  </li>
  <li>
    <p>if the size of the input is high but there are very few possible values, bucket sort beats quicksort.</p>
  </li>
  <li>
    <p>circumstances can justify using other algorithms, for example if the input is received by chunks over the network and needs to be constantly sorted, heap sort might be more adapted. </p>
  </li>
</ul>

<h2 id="google-coding">“Google coding”</h2>

<p>Applying formulas or following recipes is no substitute for an intuitive understanding of what’s happening inside your code.</p>

<p>The general spirit of not wanting to think or do math but just “have fun” or “make something awesome” results in an annoying trend: the so-called “Google coders”, people who will use Google extensively to solve their problems, copy-paste and adapt some code without fully understanding what they’re doing, not really checking the internals, or wondering why it should work.</p>

<p>It’s OK to do that sometimes, and tapping into the internet hivemind might feel like a decent way to increase your productivity instantly. But mostly it’s just laziness.</p>

<p>There are indeed a few glaring flaws with this approach:</p>

<ul>
  <li>
    <p>You end up trying to connect black boxes of code together, with potential impedance mismatch or lack of general consistency in your project.</p>
  </li>
  <li>
    <p>How do you test code you don’t understand? How do you handle memory, errors, exceptions, tests, that were not in the original code because the author wanted to keep things simple?</p>
  </li>
  <li>
    <p>You don’t learn anything that you can reapply in the future in similar circumstances using principles extracted from your intuitive comprehension of the problem.</p>
  </li>
  <li>
    <p>If you don’t understand exactly what you need in your specific problem, your solution won’t exactly answer your problem.</p>
  </li>
  <li>
    <p>No progress or breakthrough in technology was ever made by people who sacrifice for comfort the need to think. </p>
  </li>
</ul>

<p>Many programmers have the right idea when they try to roll their own piece of software (like, coding your blog platform or yet another content management system), and only then use all the available tools and libraries made by others and refined by years of use, understanding the intent behind every design decision and API call.</p>

<p>One immense advantage is that, when something breaks, you already know or imagine how the internals are made, and you can easily go fix it yourself (instead of waiting for the maintainer to manifest himself).  </p>

<p>I would only use “google coding” in emergency situations, for fun coding marathons, where I would be convinced the code quality and maintainability matters less than getting something out in record time.</p>

<h2 id="worse-than-google-coders-microsoft-black-magic-coders">Worse than “Google coders”: “Microsoft black magic coders”</h2>

<p>I’m not talking about people who work for Microsoft itself, who, I’m sure, are mostly brilliant people with a true passion for programming, for which I have a lot of respect.</p>

<p>I’m talking about people who believe they can get all the complicated parts of programming out of programming.</p>

<p>I talk to some of my friends who work and code for very big companies and are forced to use Microsoft products everywhere. </p>

<p>Microsoft products are great and make everything easier, except when they break, and they break all the time. I’m not blaming Microsoft particularly, everything breaks all the time, it’s called entropy, and it’s an inevitable part of the physical universe. Everyone can realize that programming is inherently hard, and it’s inevitable that sometimes, people will use your program in unforeseeable ways.</p>

<p>What I could blame Microsoft for, however, is that trying to hide all the implementation details and making programming simpler for a generation of subpar brainwashed programmers makes it harder to fix the inevitable problems one will encounter.</p>

<p>When something breaks in a fully open source stack, it’s relatively easy to identify which part, where, to correct the problem, to submit a fix to the maintainers, etc. It’s a very good feeling for a programmer, and it trains a generation of people who understand what happens at every level in their code, which is very sound and satisfying.</p>

<p>Microsoft deprives people from this feeling, by making the disputable (but economically justified) strategy choice to make everything “their way”, close-sourced and with voluntary divergence from internationally accepted norms or open interoperable formats.</p>

<p>Every programmer who uses Microsoft products is treated like a child, maintained in a state of voluntary ignorance, brainwashed into accepting a mix of archaic constructs and new idiomatically named features, given comparatively lower powers for fear that they could break things, and when (inevitably) something does break, no one has any idea what’s actually happening, and they are forced to call “experts” to unblock the situation.</p>

<p>I like to call them “black magic coders” because they see programming as summoning the powers of the dark side and pray that they consent to help. If Microsoft doesn’t provide any specific magical way to do what they want, they are distraught and helpless because they have no idea how to reimplement the basics by themselves.</p>

<p>I’ve talked to a software engineer with years of experience working with .Net and C#, who had no idea whether the huge web app they were making used “regular” HTTP calls or Ajax. Everything had always been abstracted away to him, to the point he had trouble making the connection between Microsoft mumbo jumbo and the actual underlying technologies used. </p>

<p>They memorize acronyms, standardized solutions, common answers good enough to pass their Microsoft certificate, and have a Pavlovian relationship to programming. </p>

<p>It’s fine to abstract away the implementation details, but only if you know what’s behind them in case you need to know, which happens often with those hard-to-find bugs where you hit a limitation or implementation quirk of the underlying technology.</p>

]]></content>
  </entry>
  
</feed>
